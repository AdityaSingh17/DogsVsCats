{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog or Cat (Image classification)\n",
    "\n",
    "## Contents\n",
    "\n",
    "### [1. Introduction](#intro)\n",
    "\n",
    "### [2. Data Preparation](#data)\n",
    "   * **Import the required libraries**\n",
    "   * **Download and unzip the dataset**\n",
    "   * **Load the data**\n",
    "   * **Split the data**\n",
    "\n",
    "### [3. Model Architecture](#cnn)\n",
    "   * **Set hyperparameters**\n",
    "   * **Define the model**\n",
    "   * **Set optimizer** \n",
    "   * **Compile model**\n",
    "   * **Data Augmentation**\n",
    "   * **Train model**\n",
    "\n",
    "### [4. Model Evaluation](#eval)\n",
    "   * **Training Accuracy vs Validation Accuracy**\n",
    "   * **Training Loss vs Validation Loss**\n",
    "   * **Model Accuracy**\n",
    "\n",
    "### [5. Prediction](#predict)\n",
    "   * **Load the test image**\n",
    "   * **Predict**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the dataset\n",
    "The dataset is comprised of photos of dogs and cats provided as a subset of photos from a much larger dataset of 3 million manually annotated photos. The dataset was developed as a partnership between Petfinder.com and Microsoft.\n",
    "The dataset was originally used as a CAPTCHA (or Completely Automated Public Turing test to tell Computers and Humans Apart), that is, a task that it is believed a human finds trivial, but cannot be solved by a machine, used on websites to distinguish between human users and bots. Specifically, the task was referred to as “ASIRRA” or Animal Species Image Recognition for Restricting Access, a type of CAPTCHA.<br>\n",
    "The dataset used for in this notebook comprises of 12500 images of cats and 12500 images of dogs, totaling to 25000 images.\n",
    "\n",
    "#### Problem statement\n",
    "Given a set of images of dogs and cats. The challenge is to investigate the available data and develop an algorithm to classify whether images contain either a dog or a cat and to develop a robust test harness for estimating the performance of the model, to explore improvements to the model. Finally, load the saved model and use it to make a prediction on a single image. A final model should typically fit on all available data, such as the combination of all train and test datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Importing libraries ... \")\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from shutil import move\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To ignore warnings generated during the run.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"[INFO] Import complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = os.getcwd()+'/cats-and-dogs.zip' # Path to the local zip file.\n",
    "image_dir = os.getcwd()+'/images' # Make a directory to store the extracted images.\n",
    "\n",
    "os.listdir(os.getcwd())\n",
    "# Check if the directory exists, if not then download the zip file.\n",
    "if os.path.exists(local_zip) == False:\n",
    "    print(\"[INFO] Downloading dataset ... \")\n",
    "    !wget --no-check-certificate \\\n",
    "        \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
    "        -O \"cats-and-dogs.zip\"\n",
    "    print(\"[INFO] Download complete!\")\n",
    "\n",
    "else: \n",
    "    print(\"[INFO] Dataset downloaded!\")\n",
    "\n",
    "# Unzip.\n",
    "if len(os.listdir(image_dir)) == 0:\n",
    "    print(\"[INFO] Unzipping dataset ... \")\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    zip_ref.extractall(image_dir)\n",
    "    zip_ref.close()\n",
    "    print(\"[INFO] Unzipping complete!\")\n",
    "\n",
    "else:\n",
    "    print(\"[INFO] Dataset unzipped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify download and extraction.\n",
    "print(len(os.listdir(image_dir+'/PetImages/Cat')))\n",
    "print(len(os.listdir(image_dir+'/PetImages/Dog')))\n",
    "# There should be 12501 images in each of the directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and testing directories both for cat images and dog images.\n",
    "try:\n",
    "    os.mkdir(image_dir+'/training')\n",
    "    os.mkdir(image_dir+'/testing')\n",
    "    os.mkdir(image_dir+'/training/cats')\n",
    "    os.mkdir(image_dir+'/training/dogs')\n",
    "    os.mkdir(image_dir+'/testing/dogs')\n",
    "    os.mkdir(image_dir+'/testing/cats')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Assign variables with path names to respective directories.\n",
    "train_dir = image_dir+'/training'\n",
    "test_dir = image_dir+'/testing'\n",
    "cat_source = image_dir+'/PetImages/Cat/'\n",
    "cat_train = image_dir+'/training/cats/'\n",
    "cat_test = image_dir+'/testing/cats/'\n",
    "dog_source = image_dir+'/PetImages/Dog/'\n",
    "dog_train = image_dir+'/training/dogs/'\n",
    "dog_test = image_dir+'/testing/dogs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset.\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(\"[INFO] \"+filename + \" is of zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files)) # Randomly shuffle the test and training set.\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        move(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        move(this_file, destination)\n",
    "        \n",
    "split_size = 0.9 # 90% train set, 10% test set.\n",
    "print(\"[INFO] Splitting dataset ...\")\n",
    "split_data(cat_source, cat_train, cat_test, split_size)\n",
    "split_data(dog_source, dog_train, dog_test, split_size)\n",
    "print(\"[INFO] Splitting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cnn\"></a>\n",
    "### 3. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (150, 150, 3)\n",
    "TARGET_SHAPE = (150,150)\n",
    "BS = 20\n",
    "INIT_LR = 1e-3\n",
    "EPOCHS = 100\n",
    "VERBOSE = 2\n",
    "STEPS = 100\n",
    "VAL_STEPS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Layer 1\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # Layer 2\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Layer 3\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    # Layer 4\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Dense Layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Output Layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the Root Mean Square (RMS) optimizer function.\n",
    "OPT = tf.keras.optimizers.RMSprop(lr = INIT_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have to classify the image into one of the two classes, we use the binary crossentropy loss function.\n",
    "model.compile(optimizer = OPT, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Get the model summary.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "This helps us in exponentially increasing the dataset for training the network by applying at random a number of transformation functions to the image.<br>\n",
    "It is to be noted that these functions do not alter the existing images, all these transformations are applied during the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the image data generator class to perform image augmentation.\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255, # Rescale the pixel values so that they are <= 1.\n",
    "      rotation_range = 40, # Randomly rotate the images.\n",
    "      width_shift_range = 0.2, # 20% shift in widht, randomly.\n",
    "      height_shift_range = 0.2, # 20% shift in height, randomly.\n",
    "      shear_range = 0.2, # 20% shear, randomly.\n",
    "      zoom_range = 0.2, # Randomly zoom into the images, zoom upto 20%.\n",
    "      horizontal_flip = True, # Flip the image, randomly.\n",
    "      fill_mode = 'nearest')\n",
    "\n",
    "# Augmentation is only needed for the training set, not for testing set.\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "print(\"[INFO] Training:\")\n",
    "# Generate augmented data, for training images.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size = TARGET_SHAPE,  # All images will be resized to 150x150\n",
    "        class_mode = 'binary', # Since we use binary_crossentropy loss, we need binary labels\n",
    "        batch_size = BS)\n",
    "\n",
    "print(\"[INFO] Testing:\")\n",
    "# Generate augmented data, for testing images.\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        test_dir, # This is the source directory for testing images\n",
    "        target_size = TARGET_SHAPE,\n",
    "        class_mode = 'binary',\n",
    "        batch_size = BS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint after every second epoch.\n",
    "checkpoint = ModelCheckpoint(\"DogOrCat.h5\", monitor = 'val_loss', verbose = 2, save_best_only = True, save_weights_only = False, mode = 'auto', period = 1)\n",
    "\n",
    "# Train the model and record per epoch observations in history.\n",
    "print(\"[INFO] Training model ...\")\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = STEPS, \n",
    "      epochs = EPOCHS,\n",
    "      validation_data = validation_generator,\n",
    "      callbacks = [checkpoint],\n",
    "      validation_steps = VAL_STEPS,\n",
    "      verbose = VERBOSE)\n",
    "print(\"[INFO] Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accuracy vs Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0\n",
    "xmax = 20\n",
    "ymin = 0.0\n",
    "ymax = 1.0\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([xmin,xmax])\n",
    "axes.set_ylim([ymin,ymax])\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label = 'Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss vs Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([xmin,xmax])\n",
    "axes.set_ylim([ymin,ymax])\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label = 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(validation_generator)\n",
    "print(\"[INFO] Model accuracy = \", scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predict\"></a>\n",
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the test image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
