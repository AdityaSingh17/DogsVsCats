{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog or Cat (Image classification)\n",
    "\n",
    "## Contents\n",
    "\n",
    "### [1. Introduction](#intro)\n",
    "\n",
    "### [2. Data Preparation](#data)\n",
    "   * **Import the required libraries**\n",
    "   * **Download and unzip the dataset**\n",
    "   * **Load the data**\n",
    "   * **Split the data**\n",
    "\n",
    "### [3. Model Architecture](#cnn)\n",
    "   * **Define the model**\n",
    "   * **Set hyperparameters**\n",
    "   * **Set optimizer** \n",
    "   * **Compile model**\n",
    "   * **Data Augmentation**\n",
    "   * **Train model**\n",
    "\n",
    "### [4. Model Evaluation](#eval)\n",
    "   * **Training Accuracy vs Validation Accuracy**\n",
    "   * **Training Loss vs Validation Loss**\n",
    "   * **Model Accuracy**\n",
    "\n",
    "### [5. Test the model](#test)\n",
    "   * **Load the test image**\n",
    "   * **Predict**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the dataset\n",
    "The dataset is comprised of photos of dogs and cats provided as a subset of photos from a much larger dataset of 3 million manually annotated photos. The dataset was developed as a partnership between Petfinder.com and Microsoft.\n",
    "The dataset was originally used as a CAPTCHA (or Completely Automated Public Turing test to tell Computers and Humans Apart), that is, a task that it is believed a human finds trivial, but cannot be solved by a machine, used on websites to distinguish between human users and bots. Specifically, the task was referred to as “ASIRRA” or Animal Species Image Recognition for Restricting Access, a type of CAPTCHA.<br>\n",
    "The dataset used for in this notebook comprises of 12500 images of cats and 12500 images of dogs, totaling to 25000 images.\n",
    "\n",
    "#### Problem statement\n",
    "Given a set of images of dogs and cats. The challenge is to investigate the available data and develop an algorithm to classify whether images contain either a dog or a cat and to develop a robust test harness for estimating the performance of the model, to explore improvements to the model. Finally, load the saved model and use it to make a prediction on a single image. A final model should typically fit on all available data, such as the combination of all train and test datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Importing libraries ... \n",
      "[INFO] Import complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Importing libraries ... \")\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "print(\"[INFO] Import complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset already downloaded!\n",
      "[INFO] Unzipping dataset ... \n",
      "[INFO] Unzipping complete!\n"
     ]
    }
   ],
   "source": [
    "local_zip = os.getcwd()+'/cats-and-dogs.zip' # Path to the local zip file.\n",
    "image_dir = os.getcwd()+'/images' # Make a directory to store the extracted images.\n",
    "\n",
    "os.listdir(os.getcwd())\n",
    "# Check if the directory exists, if not then download the zip file.\n",
    "if os.path.exists(local_zip) == False:\n",
    "    print(\"[INFO] Downloading dataset ... \")\n",
    "    !wget --no-check-certificate \\\n",
    "        \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
    "        -O \"cats-and-dogs.zip\"\n",
    "    print(\"[INFO] Download complete!\")\n",
    "\n",
    "else: \n",
    "    print(\"[INFO] Dataset already downloaded!\")\n",
    "# Unzip.\n",
    "print(\"[INFO] Unzipping dataset ... \")\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(image_dir)\n",
    "zip_ref.close()\n",
    "print(\"[INFO] Unzipping complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PetImages', 'testing', 'readme[1].txt', 'MSR-LA - 3467.docx', 'training']\n",
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "# Verify download and extraction.\n",
    "print(os.listdir(image_dir))\n",
    "print(len(os.listdir(image_dir+'/PetImages/Cat')))\n",
    "print(len(os.listdir(image_dir+'/PetImages/Dog')))\n",
    "# The image_dir should contain the following files/directories: PetImages, readme[1].txt, MSR-LA - 3467.docx\n",
    "# There should be 12501 images in each of the directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and testing directories both for cat images and dog images.\n",
    "try:\n",
    "    os.mkdir(image_dir+'/training')\n",
    "    os.mkdir(image_dir+'/testing')\n",
    "    os.mkdir(image_dir+'/training/cats')\n",
    "    os.mkdir(image_dir+'/training/dogs')\n",
    "    os.mkdir(image_dir+'/testing/dogs')\n",
    "    os.mkdir(image_dir+'/testing/cats')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Assign variables with path names to respective directories.\n",
    "cat_source = image_dir+'/PetImages/Cat/'\n",
    "cat_train = image_dir+'/training/cats'\n",
    "cat_test = image_dir+'/testing/cats'\n",
    "dog_source = image_dir+'/PetImages/Dog/'\n",
    "dog_train = image_dir+'/training/dogs'\n",
    "dog_test = image_dir+'/testing/dogs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Splitting dataset ...\n",
      "[INFO] 666.jpg is of zero length, so ignoring.\n",
      "[INFO] 11702.jpg is of zero length, so ignoring.\n",
      "[INFO] Splitting complete!\n"
     ]
    }
   ],
   "source": [
    "# Function to split the dataset.\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(\"[INFO] \"+filename + \" is of zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files)) # Randomly shuffle the test and training set.\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)\n",
    "        \n",
    "split_size = 0.9 # 90% train set, 10% test set.\n",
    "print(\"[INFO] Splitting dataset ...\")\n",
    "split_data(cat_source, cat_train, cat_test, split_size)\n",
    "split_data(dog_source, dog_train, dog_test, split_size)\n",
    "print(\"[INFO] Splitting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cnn\"></a>\n",
    "### 3. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accuracy vs Validation Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss vs Validation Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test\"></a>\n",
    "### 5. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the test image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
